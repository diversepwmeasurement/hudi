concurrency:
  cancel-in-progress: ${{ !contains(github.ref, 'master') && !contains(github.ref,
    'branch-0.x') && !contains(github.ref, 'release-') }}
  group: ${{ github.ref }}
env:
  MVN_ARGS: -e -ntp -B -V -Dgpg.skip -Djacoco.skip -Pwarn-log -Dorg.slf4j.simpleLogger.log.org.apache.maven.plugins.shade=warn
    -Dorg.slf4j.simpleLogger.log.org.apache.maven.plugins.dependency=warn -Dmaven.wagon.httpconnectionManager.ttlSeconds=25
    -Dmaven.wagon.http.retryHandler.count=5
  SPARK_COMMON_MODULES: hudi-spark-datasource/hudi-spark,hudi-spark-datasource/hudi-spark-common
jobs:
  docker-java17-test:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v3
    - continue-on-error: true
      name: Set up JDK 8
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '8'
    - continue-on-error: true
      env:
        FLINK_PROFILE: ${{ matrix.flinkProfile }}
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
        SPARK_RUNTIME: ${{ matrix.sparkRuntime }}
      if: ${{ env.SPARK_PROFILE >= 'spark3.4' }}
      name: UT/FT - Docker Test - OpenJDK 17
      run: 'HUDI_VERSION=$(mvn help:evaluate -Dexpression=project.version -q -DforceStdout)

        ./packaging/bundle-validation/run_docker_java17.sh

        '
    strategy:
      matrix:
        include:
        - flinkProfile: flink1.18
          scalaProfile: scala-2.13
          sparkProfile: spark3.5
          sparkRuntime: spark3.5.0
        - flinkProfile: flink1.18
          scalaProfile: scala-2.12
          sparkProfile: spark3.5
          sparkRuntime: spark3.5.0
        - flinkProfile: flink1.18
          scalaProfile: scala-2.12
          sparkProfile: spark3.4
          sparkRuntime: spark3.4.0
  integration-tests:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v3
    - continue-on-error: true
      name: Set up JDK 8
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '8'
    - continue-on-error: true
      env:
        SCALA_PROFILE: -Dscala-2.11 -Dscala.binary.version=2.11
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Build Project
      run: mvn clean install -T 2 $SCALA_PROFILE -D"$SPARK_PROFILE" -Pintegration-tests
        -DskipTests=true $MVN_ARGS
    - continue-on-error: true
      env:
        SCALA_PROFILE: -Dscala-2.11 -Dscala.binary.version=2.11
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: UT integ-test
      run: mvn test $SCALA_PROFILE -D"$SPARK_PROFILE" -Pintegration-tests -DskipUTs=false
        -DskipITs=true -pl hudi-integ-test $MVN_ARGS
    - continue-on-error: true
      env:
        SCALA_PROFILE: -Dscala-2.11 -Dscala.binary.version=2.11
        SPARK_ARCHIVE: ${{ matrix.sparkArchive }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: IT
      run: 'echo "Downloading $SPARK_ARCHIVE"

        curl https://archive.apache.org/dist/spark/$SPARK_ARCHIVE --create-dirs -o
        $GITHUB_WORKSPACE/$SPARK_ARCHIVE

        tar -xvf $GITHUB_WORKSPACE/$SPARK_ARCHIVE -C $GITHUB_WORKSPACE/

        mkdir /tmp/spark-events/

        SPARK_ARCHIVE_BASENAME=$(basename $SPARK_ARCHIVE)

        export SPARK_HOME=$GITHUB_WORKSPACE/${SPARK_ARCHIVE_BASENAME%.*}

        rm -f $GITHUB_WORKSPACE/$SPARK_ARCHIVE

        docker system prune --all --force

        mvn verify $SCALA_PROFILE -D"$SPARK_PROFILE" -Pintegration-tests -pl !hudi-flink-datasource/hudi-flink
        $MVN_ARGS

        '
    strategy:
      matrix:
        include:
        - sparkArchive: spark-2.4.4/spark-2.4.4-bin-hadoop2.7.tgz
          sparkProfile: spark2.4
  test-flink:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v3
    - continue-on-error: true
      name: Set up JDK 8
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '8'
    - continue-on-error: true
      env:
        FLINK_PROFILE: ${{ matrix.flinkProfile }}
        SCALA_PROFILE: scala-2.12
      name: Build Project
      run: mvn clean install -T 2 -D"$SCALA_PROFILE" -D"$FLINK_PROFILE" -pl hudi-examples/hudi-examples-flink
        -am -Davro.version=1.10.0 -DskipTests=true $MVN_ARGS
    - continue-on-error: true
      env:
        FLINK_PROFILE: ${{ matrix.flinkProfile }}
        SCALA_PROFILE: scala-2.12
      name: Quickstart Test
      run: mvn test -Punit-tests -D"$SCALA_PROFILE" -D"$FLINK_PROFILE" -pl hudi-examples/hudi-examples-flink
        $MVN_ARGS
    - continue-on-error: true
      env:
        FLINK_PROFILE: ${{ matrix.flinkProfile }}
        SCALA_PROFILE: scala-2.12
      if: ${{ endsWith(env.FLINK_PROFILE, '1.18') }}
      name: Integration Test
      run: 'mvn clean install -T 2 -Pintegration-tests -D"$SCALA_PROFILE" -D"$FLINK_PROFILE"
        -pl hudi-flink-datasource/hudi-flink -am -Davro.version=1.10.0 -DskipTests=true
        $MVN_ARGS

        mvn verify -Pintegration-tests -D"$SCALA_PROFILE" -D"$FLINK_PROFILE" -pl hudi-flink-datasource/hudi-flink
        $MVN_ARGS

        '
    strategy:
      matrix:
        include:
        - flinkProfile: flink1.14
        - flinkProfile: flink1.15
        - flinkProfile: flink1.16
        - flinkProfile: flink1.17
        - flinkProfile: flink1.18
  test-hudi-hadoop-mr-and-hudi-java-client:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v3
    - continue-on-error: true
      name: Set up JDK 8
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '8'
    - continue-on-error: true
      name: Generate Maven Wrapper
      run: mvn -N io.takari:maven:wrapper
    - continue-on-error: true
      env:
        FLINK_PROFILE: ${{ matrix.flinkProfile }}
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Build Project
      run: ./mvnw clean install -T 2 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -D"FLINK_PROFILE"
        -DskipTests=true -Phudi-platform-service $MVN_ARGS -am -pl hudi-hadoop-mr,hudi-client/hudi-java-client
    - continue-on-error: true
      env:
        FLINK_PROFILE: ${{ matrix.flinkProfile }}
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: UT - hudi-hadoop-mr and hudi-client/hudi-java-client
      run: ./mvnw test -Punit-tests -fae -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -D"FLINK_PROFILE"
        -pl hudi-hadoop-mr,hudi-client/hudi-java-client $MVN_ARGS
    strategy:
      matrix:
        include:
        - flinkProfile: flink1.18
          scalaProfile: scala-2.12
          sparkProfile: spark3.2
    timeout-minutes: 40
  test-spark-java-tests:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v3
    - continue-on-error: true
      name: Set up JDK 8
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '8'
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Build Project
      run: mvn clean install -T 2 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -DskipTests=true
        $MVN_ARGS -am -pl "hudi-examples/hudi-examples-spark,$SPARK_COMMON_MODULES,$SPARK_MODULES"
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Quickstart Test
      run: mvn test -Punit-tests -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -pl hudi-examples/hudi-examples-spark
        $MVN_ARGS
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_MODULES: ${{ matrix.sparkModules }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      if: ${{ !endsWith(env.SPARK_PROFILE, '3.2') }}
      name: Java UT - Common & Spark
      run: mvn test -Punit-tests -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -DwildcardSuites=skipScalaTests
        -DfailIfNoTests=false -pl "$SPARK_COMMON_MODULES,$SPARK_MODULES" $MVN_ARGS
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_MODULES: ${{ matrix.sparkModules }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      if: ${{ !endsWith(env.SPARK_PROFILE, '3.2') }}
      name: Java FT - Spark
      run: mvn test -Pfunctional-tests -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -DwildcardSuites=skipScalaTests
        -DfailIfNoTests=false -pl "$SPARK_COMMON_MODULES,$SPARK_MODULES" $MVN_ARGS
    strategy:
      matrix:
        include:
        - scalaProfile: scala-2.11
          sparkModules: hudi-spark-datasource/hudi-spark2
          sparkProfile: spark2.4
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.0.x
          sparkProfile: spark3.0
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.1.x
          sparkProfile: spark3.1
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.2.x
          sparkProfile: spark3.2
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.3.x
          sparkProfile: spark3.3
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.4.x
          sparkProfile: spark3.4
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.5.x
          sparkProfile: spark3.5
        - scalaProfile: scala-2.13
          sparkModules: hudi-spark-datasource/hudi-spark3.5.x
          sparkProfile: spark3.5
  test-spark-java11-17-java-tests:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v3
    - continue-on-error: true
      name: Set up JDK 11
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '11'
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Build Project
      run: mvn clean install -T 2 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -DskipTests=true
        $MVN_ARGS -am -pl "hudi-examples/hudi-examples-spark,hudi-common,$SPARK_COMMON_MODULES,$SPARK_MODULES"
    - continue-on-error: true
      name: Set up JDK 17
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '17'
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Quickstart Test
      run: mvn test -Punit-tests -Pjava17 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -DwildcardSuites=skipScalaTests
        -DfailIfNoTests=false -pl hudi-examples/hudi-examples-spark $MVN_ARGS
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_MODULES: ${{ matrix.sparkModules }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Java UT - Common & Spark
      run: mvn test -Punit-tests -Pjava17 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -DwildcardSuites=skipScalaTests
        -DfailIfNoTests=false -pl "hudi-common,$SPARK_COMMON_MODULES,$SPARK_MODULES"
        $MVN_ARGS
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_MODULES: ${{ matrix.sparkModules }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Java FT - Spark
      run: mvn test -Pfunctional-tests -Pjava17 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE"
        -pl "$SPARK_COMMON_MODULES,$SPARK_MODULES" $MVN_ARGS
    strategy:
      matrix:
        include:
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.5.x
          sparkProfile: spark3.5
        - scalaProfile: scala-2.13
          sparkModules: hudi-spark-datasource/hudi-spark3.5.x
          sparkProfile: spark3.5
  test-spark-java11-17-scala-tests:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v3
    - continue-on-error: true
      name: Set up JDK 11
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '11'
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Build Project
      run: mvn clean install -T 2 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -DskipTests=true
        $MVN_ARGS -am -pl "hudi-examples/hudi-examples-spark,hudi-common,$SPARK_COMMON_MODULES,$SPARK_MODULES"
    - continue-on-error: true
      name: Set up JDK 17
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '17'
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_MODULES: ${{ matrix.sparkModules }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Scala UT - Common & Spark
      run: mvn test -Punit-tests -Pjava17 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -Dtest=skipJavaTests
        -DfailIfNoTests=false -pl "hudi-common,$SPARK_COMMON_MODULES,$SPARK_MODULES"
        $MVN_ARGS
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_MODULES: ${{ matrix.sparkModules }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Scala FT - Spark
      run: mvn test -Pfunctional-tests -Pjava17 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE"
        -Dtest=skipJavaTests -DfailIfNoTests=false -pl "$SPARK_COMMON_MODULES,$SPARK_MODULES"
        $MVN_ARGS
    strategy:
      matrix:
        include:
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.5.x
          sparkProfile: spark3.5
        - scalaProfile: scala-2.13
          sparkModules: hudi-spark-datasource/hudi-spark3.5.x
          sparkProfile: spark3.5
  test-spark-java17-java-tests:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v3
    - continue-on-error: true
      name: Set up JDK 8
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '8'
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Build Project
      run: mvn clean install -T 2 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -DskipTests=true
        $MVN_ARGS -am -pl "hudi-examples/hudi-examples-spark,hudi-common,$SPARK_COMMON_MODULES,$SPARK_MODULES"
    - continue-on-error: true
      name: Set up JDK 17
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '17'
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Quickstart Test
      run: mvn test -Punit-tests -Pjava17 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -DwildcardSuites=skipScalaTests
        -DfailIfNoTests=false -pl hudi-examples/hudi-examples-spark $MVN_ARGS
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_MODULES: ${{ matrix.sparkModules }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Java UT - Common & Spark
      run: mvn test -Punit-tests -Pjava17 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -DwildcardSuites=skipScalaTests
        -DfailIfNoTests=false -pl "hudi-common,$SPARK_COMMON_MODULES,$SPARK_MODULES"
        $MVN_ARGS
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_MODULES: ${{ matrix.sparkModules }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Java FT - Spark
      run: mvn test -Pfunctional-tests -Pjava17 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE"
        -pl "$SPARK_COMMON_MODULES,$SPARK_MODULES" $MVN_ARGS
    strategy:
      matrix:
        include:
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.3.x
          sparkProfile: spark3.3
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.4.x
          sparkProfile: spark3.4
  test-spark-java17-scala-tests:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v3
    - continue-on-error: true
      name: Set up JDK 8
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '8'
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Build Project
      run: mvn clean install -T 2 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -DskipTests=true
        $MVN_ARGS -am -pl "hudi-examples/hudi-examples-spark,hudi-common,$SPARK_COMMON_MODULES,$SPARK_MODULES"
    - continue-on-error: true
      name: Set up JDK 17
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '17'
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_MODULES: ${{ matrix.sparkModules }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Scala UT - Common & Spark
      run: mvn test -Punit-tests -Pjava17 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -Dtest=skipJavaTests
        -DfailIfNoTests=false -pl "hudi-common,$SPARK_COMMON_MODULES,$SPARK_MODULES"
        $MVN_ARGS
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_MODULES: ${{ matrix.sparkModules }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Scala FT - Spark
      run: mvn test -Pfunctional-tests -Pjava17 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE"
        -Dtest=skipJavaTests -DfailIfNoTests=false -pl "$SPARK_COMMON_MODULES,$SPARK_MODULES"
        $MVN_ARGS
    strategy:
      matrix:
        include:
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.3.x
          sparkProfile: spark3.3
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.4.x
          sparkProfile: spark3.4
  test-spark-scala-tests:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v3
    - continue-on-error: true
      name: Set up JDK 8
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '8'
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Build Project
      run: mvn clean install -T 2 -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -DskipTests=true
        $MVN_ARGS -am -pl "hudi-examples/hudi-examples-spark,$SPARK_COMMON_MODULES,$SPARK_MODULES"
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_MODULES: ${{ matrix.sparkModules }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      if: ${{ !endsWith(env.SPARK_PROFILE, '3.2') }}
      name: Scala UT - Common & Spark
      run: mvn test -Punit-tests -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -Dtest=skipJavaTests
        -DfailIfNoTests=false -pl "$SPARK_COMMON_MODULES,$SPARK_MODULES" $MVN_ARGS
    - continue-on-error: true
      env:
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_MODULES: ${{ matrix.sparkModules }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      if: ${{ !endsWith(env.SPARK_PROFILE, '3.2') }}
      name: Scala FT - Spark
      run: mvn test -Pfunctional-tests -D"$SCALA_PROFILE" -D"$SPARK_PROFILE" -Dtest=skipJavaTests
        -DfailIfNoTests=false -pl "$SPARK_COMMON_MODULES,$SPARK_MODULES" $MVN_ARGS
    strategy:
      matrix:
        include:
        - scalaProfile: scala-2.11
          sparkModules: hudi-spark-datasource/hudi-spark2
          sparkProfile: spark2.4
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.0.x
          sparkProfile: spark3.0
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.1.x
          sparkProfile: spark3.1
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.2.x
          sparkProfile: spark3.2
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.3.x
          sparkProfile: spark3.3
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.4.x
          sparkProfile: spark3.4
        - scalaProfile: scala-2.12
          sparkModules: hudi-spark-datasource/hudi-spark3.5.x
          sparkProfile: spark3.5
        - scalaProfile: scala-2.13
          sparkModules: hudi-spark-datasource/hudi-spark3.5.x
          sparkProfile: spark3.5
  validate-bundles:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v3
    - continue-on-error: true
      name: Set up JDK 8
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '8'
    - continue-on-error: true
      env:
        FLINK_PROFILE: ${{ matrix.flinkProfile }}
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Build Project
      run: "if [ \"$SCALA_PROFILE\" == \"scala-2.13\" ]; then\n  mvn clean package\
        \ -T 2 -D\"$SCALA_PROFILE\" -D\"$SPARK_PROFILE\" -DdeployArtifacts=true -DskipTests=true\
        \ $MVN_ARGS -pl packaging/hudi-hadoop-mr-bundle,packaging/hudi-spark-bundle,packaging/hudi-utilities-bundle,packaging/hudi-utilities-slim-bundle\
        \ -am\nelse\n  mvn clean package -T 2 -D\"$SCALA_PROFILE\" -D\"$SPARK_PROFILE\"\
        \ -DdeployArtifacts=true -DskipTests=true $MVN_ARGS\n  # TODO remove the sudo\
        \ below. It's a needed workaround as detailed in HUDI-5708.\n  sudo chown\
        \ -R \"$USER:$(id -g -n)\" hudi-platform-service/hudi-metaserver/target/generated-sources\n\
        \  mvn clean package -T 2 -D\"$SCALA_PROFILE\" -D\"$FLINK_PROFILE\" -DdeployArtifacts=true\
        \ -DskipTests=true $MVN_ARGS -pl packaging/hudi-flink-bundle -am -Davro.version=1.10.0\n\
        fi\n"
    - continue-on-error: true
      env:
        FLINK_PROFILE: ${{ matrix.flinkProfile }}
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
        SPARK_RUNTIME: ${{ matrix.sparkRuntime }}
      if: ${{ env.SPARK_PROFILE >= 'spark3' }}
      name: IT - Bundle Validation - OpenJDK 8
      run: 'HUDI_VERSION=$(mvn help:evaluate -Dexpression=project.version -q -DforceStdout)

        ./packaging/bundle-validation/ci_run.sh hudi_docker_java8 $HUDI_VERSION openjdk8

        '
    - continue-on-error: true
      env:
        FLINK_PROFILE: ${{ matrix.flinkProfile }}
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
        SPARK_RUNTIME: ${{ matrix.sparkRuntime }}
      if: ${{ env.SPARK_PROFILE >= 'spark3' }}
      name: IT - Bundle Validation - OpenJDK 11
      run: 'HUDI_VERSION=$(mvn help:evaluate -Dexpression=project.version -q -DforceStdout)

        ./packaging/bundle-validation/ci_run.sh hudi_docker_java11 $HUDI_VERSION openjdk11

        '
    - continue-on-error: true
      env:
        FLINK_PROFILE: ${{ matrix.flinkProfile }}
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
        SPARK_RUNTIME: ${{ matrix.sparkRuntime }}
      if: ${{ env.SPARK_PROFILE >= 'spark3.3' }}
      name: IT - Bundle Validation - OpenJDK 17
      run: 'HUDI_VERSION=$(mvn help:evaluate -Dexpression=project.version -q -DforceStdout)

        ./packaging/bundle-validation/ci_run.sh hudi_docker_java17 $HUDI_VERSION openjdk17

        '
    strategy:
      matrix:
        include:
        - flinkProfile: flink1.18
          scalaProfile: scala-2.13
          sparkProfile: spark3.5
          sparkRuntime: spark3.5.0
        - flinkProfile: flink1.18
          scalaProfile: scala-2.12
          sparkProfile: spark3.5
          sparkRuntime: spark3.5.0
        - flinkProfile: flink1.18
          scalaProfile: scala-2.12
          sparkProfile: spark3.4
          sparkRuntime: spark3.4.0
        - flinkProfile: flink1.17
          scalaProfile: scala-2.12
          sparkProfile: spark3.3
          sparkRuntime: spark3.3.2
        - flinkProfile: flink1.16
          scalaProfile: scala-2.12
          sparkProfile: spark3.3
          sparkRuntime: spark3.3.1
        - flinkProfile: flink1.15
          scalaProfile: scala-2.12
          sparkProfile: spark3.2
          sparkRuntime: spark3.2.3
        - flinkProfile: flink1.14
          scalaProfile: scala-2.12
          sparkProfile: spark3.1
          sparkRuntime: spark3.1.3
        - flinkProfile: flink1.14
          scalaProfile: scala-2.12
          sparkProfile: spark3.0
          sparkRuntime: spark3.0.2
        - flinkProfile: flink1.14
          scalaProfile: scala-2.12
          sparkProfile: spark2.4
          sparkRuntime: spark2.4.8
  validate-bundles-java11:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v3
    - continue-on-error: true
      name: Set up JDK 11
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '11'
    - continue-on-error: true
      env:
        FLINK_PROFILE: ${{ matrix.flinkProfile }}
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
      name: Build Project
      run: "if [ \"$SCALA_PROFILE\" == \"scala-2.13\" ]; then\n  mvn clean package\
        \ -T 2 -D\"$SCALA_PROFILE\" -D\"$SPARK_PROFILE\" -DdeployArtifacts=true -DskipTests=true\
        \ $MVN_ARGS -Dmaven.javadoc.skip=true -pl packaging/hudi-hadoop-mr-bundle,packaging/hudi-spark-bundle,packaging/hudi-utilities-bundle,packaging/hudi-utilities-slim-bundle\
        \ -am\nelse\n  mvn clean package -T 2 -D\"$SCALA_PROFILE\" -D\"$SPARK_PROFILE\"\
        \ -DdeployArtifacts=true -DskipTests=true $MVN_ARGS -Dmaven.javadoc.skip=true\n\
        \  # TODO remove the sudo below. It's a needed workaround as detailed in HUDI-5708.\n\
        \  sudo chown -R \"$USER:$(id -g -n)\" hudi-platform-service/hudi-metaserver/target/generated-sources\n\
        \  mvn clean package -T 2 -D\"$SCALA_PROFILE\" -D\"$FLINK_PROFILE\" -DdeployArtifacts=true\
        \ -DskipTests=true $MVN_ARGS -Dmaven.javadoc.skip=true -pl packaging/hudi-flink-bundle\
        \ -am -Davro.version=1.10.0\nfi\n"
    - continue-on-error: true
      env:
        FLINK_PROFILE: ${{ matrix.flinkProfile }}
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
        SPARK_RUNTIME: ${{ matrix.sparkRuntime }}
      name: IT - Bundle Validation - OpenJDK 11
      run: 'HUDI_VERSION=$(mvn help:evaluate -Dexpression=project.version -q -DforceStdout)

        ./packaging/bundle-validation/ci_run.sh hudi_docker_java11 $HUDI_VERSION openjdk11

        '
    - continue-on-error: true
      env:
        FLINK_PROFILE: ${{ matrix.flinkProfile }}
        SCALA_PROFILE: ${{ matrix.scalaProfile }}
        SPARK_PROFILE: ${{ matrix.sparkProfile }}
        SPARK_RUNTIME: ${{ matrix.sparkRuntime }}
      name: IT - Bundle Validation - OpenJDK 17
      run: 'HUDI_VERSION=$(mvn help:evaluate -Dexpression=project.version -q -DforceStdout)

        ./packaging/bundle-validation/ci_run.sh hudi_docker_java17 $HUDI_VERSION openjdk17

        '
    strategy:
      matrix:
        include:
        - flinkProfile: flink1.18
          scalaProfile: scala-2.13
          sparkProfile: spark3.5
          sparkRuntime: spark3.5.0
        - flinkProfile: flink1.18
          scalaProfile: scala-2.12
          sparkProfile: spark3.5
          sparkRuntime: spark3.5.0
  validate-source:
    runs-on: self-hosted
    steps:
    - continue-on-error: true
      uses: actions/checkout@v3
    - continue-on-error: true
      name: Set up JDK 8
      uses: actions/setup-java@v3
      with:
        architecture: x64
        cache: maven
        distribution: temurin
        java-version: '8'
    - continue-on-error: true
      name: Check Binary Files
      run: ./scripts/release/validate_source_binary_files.sh
    - continue-on-error: true
      name: Check Copyright
      run: './scripts/release/create_source_directory.sh hudi-tmp-repo

        cd hudi-tmp-repo

        ./scripts/release/validate_source_copyright.sh

        '
    - continue-on-error: true
      name: RAT check
      run: ./scripts/release/validate_source_rat.sh
name: Java CI
on:
  repository_dispatch:
    types: trigger-ga___bot.yml
